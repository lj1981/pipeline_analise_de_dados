import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from datetime import datetime

# Caminho do dataset e pasta de sa√≠da
DATA_PATH = "/home/luiz/Downloads/Projetos_One/machine_learning/dataset_clientes_final.csv"
OUTPUT_DIR = "./analysis_results"
os.makedirs(OUTPUT_DIR, exist_ok=True)  # Garante que a pasta existe


def load_data():
    """Carrega o dataset e verifica se n√£o est√° vazio."""
    try:
        df = pd.read_csv(DATA_PATH, encoding='utf-8', sep=',')
        if df.empty:
            print(" O arquivo foi carregado, mas est√° vazio!")
            return None
        print(f" Dataset carregado com {df.shape[0]} linhas e {df.shape[1]} colunas.")
        return df
    except Exception as e:
        print(f" Erro ao carregar o arquivo: {e}")
        return None


def optimize_memory(df):
    """Reduz uso de mem√≥ria convertendo tipos de dados."""
    for col in df.columns:
        if df[col].dtype == 'float64':
            df[col] = df[col].astype('float32')
        elif df[col].dtype == 'int64':
            df[col] = pd.to_numeric(df[col], downcast='integer')
    return df


def clean_data(df):
    """Realiza limpeza de dados e otimiza√ß√£o de mem√≥ria."""
    initial_mem = df.memory_usage().sum() / 1024 ** 2
    df = df.drop_duplicates()
    df = df.dropna(axis=1, how='all')
    df = df.dropna(thresh=0.7 * len(df), axis=1)
    final_mem = df.memory_usage().sum() / 1024 ** 2
    print(f"üìâ Mem√≥ria reduzida de {initial_mem:.2f} MB para {final_mem:.2f} MB")
    return df if df.shape[0] > 0 else None


def segment_clients(df, n_clusters=5):
    """
    Segmenta clientes usando K-Means considerando todas as colunas num√©ricas.
    Adiciona a coluna 'Cluster' com os r√≥tulos dos clusters.
    """
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    if not numeric_cols:
        print(" ERRO: Nenhuma coluna num√©rica encontrada para segmenta√ß√£o.")
        return df
    print(f"üìä Usando {len(numeric_cols)} colunas para segmenta√ß√£o: {numeric_cols}")
    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())
    scaler = StandardScaler()
    df_scaled = scaler.fit_transform(df[numeric_cols])
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    df['Cluster'] = kmeans.fit_predict(df_scaled)
    print(f" Segmenta√ß√£o conclu√≠da! Clientes classificados em {n_clusters} grupos.")
    return df


def assign_cluster_names(df, col_name='categoria'):
    """
    Para cada cluster, extrai o valor mais frequente da coluna 'col_name'
    e retorna um dicion√°rio mapeando o n√∫mero do cluster para o nome real.
    Se a coluna n√£o existir, usa r√≥tulos padr√£o.
    """
    cluster_names = {}
    if col_name not in df.columns:
        print(f"Coluna '{col_name}' n√£o encontrada. Usando labels padr√£o.")
        for cluster in df['Cluster'].unique():
            cluster_names[cluster] = f"Cluster {cluster}"
        return cluster_names

    for cluster in df['Cluster'].unique():
        mode_value = df[df['Cluster'] == cluster][col_name].mode()
        if not mode_value.empty:
            cluster_names[cluster] = mode_value.iloc[0]
        else:
            cluster_names[cluster] = f"Cluster {cluster}"
    return cluster_names


def comprehensive_eda(df):
    """
    Gera um EDA completo, explorando todas as colunas (num√©ricas e categ√≥ricas),
    salvando gr√°ficos e estat√≠sticas para fornecer um relat√≥rio rico.
    """
    # 1) Sum√°rio de valores ausentes
    missing_summary = df.isnull().sum().sort_values(ascending=False)
    missing_summary.to_csv(f"{OUTPUT_DIR}/missing_summary.csv")
    print("üìã Sum√°rio de valores ausentes salvo em missing_summary.csv")

    # 2) Estat√≠sticas descritivas para colunas num√©ricas
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    if numeric_cols:
        desc_stats = df[numeric_cols].describe().T
        desc_stats.to_csv(f"{OUTPUT_DIR}/numeric_descriptive_stats.csv")
        print("üìä Estat√≠sticas descritivas das colunas num√©ricas salvas em numeric_descriptive_stats.csv")

    # 3) Frequ√™ncias para colunas categ√≥ricas
    cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
    if cat_cols:
        freq_report = {}
        for c in cat_cols:
            freq = df[c].value_counts(dropna=False).head(50)  # Top 50 valores
            freq_report[c] = freq
            freq.to_csv(f"{OUTPUT_DIR}/freq_{c}.csv")
        print(" Frequ√™ncias das colunas categ√≥ricas salvas em arquivos separados.")

    # 4) Matriz de correla√ß√£o para colunas num√©ricas
    if len(numeric_cols) > 1:
        corr_matrix = df[numeric_cols].corr()
        plt.figure(figsize=(10, 8))
        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f")
        plt.title('Matriz de Correla√ß√£o (todas as colunas num√©ricas)')
        plt.savefig(f"{OUTPUT_DIR}/correlation_matrix_all_numeric.png")
        plt.close()
        print(" Matriz de correla√ß√£o de todas as colunas num√©ricas salva.")

    # 5) Gr√°ficos de cada coluna
    # 5a) Para colunas num√©ricas: histograma e boxplot
    for col in numeric_cols:
        # Histograma
        plt.figure(figsize=(8, 5))
        sns.histplot(df[col], kde=True)
        plt.title(f'Histograma de {col}')
        plt.savefig(f"{OUTPUT_DIR}/hist_{col}.png")
        plt.close()

        # Boxplot
        plt.figure(figsize=(8, 5))
        sns.boxplot(x=df[col])
        plt.title(f'Boxplot de {col}')
        plt.savefig(f"{OUTPUT_DIR}/box_{col}.png")
        plt.close()

    # 5b) Para colunas categ√≥ricas: gr√°fico de barras com porcentagens (MODIFICADO)
    for col in cat_cols:
        plt.figure(figsize=(10, 6))
        # Calculando valores e porcentagens
        value_counts = df[col].value_counts(dropna=False).nlargest(20)
        total = len(df[col])
        percentages = (value_counts / total * 100).round(1)

        # Plotando
        ax = sns.barplot(x=value_counts.index, y=value_counts.values, palette="viridis")

        # Adicionando porcentagens
        for i, p in enumerate(ax.patches):
            height = p.get_height()
            ax.text(p.get_x() + p.get_width() / 2., height + 3,
                    f'{percentages.iloc[i]}%',
                    ha="center", va="bottom", fontsize=9, rotation=45)

        plt.xticks(rotation=45, ha='right')
        plt.title(f'Distribui√ß√£o de {col} (Top 20)')
        plt.tight_layout()
        plt.savefig(f"{OUTPUT_DIR}/bar_{col}.png")
        plt.close()

    # 6) Sum√°rios por cluster, se existir (MODIFICADO)
    if 'ClusterLabel' in df.columns:
        # Estat√≠sticas num√©ricas por ClusterLabel
        cluster_numeric_mean = df.groupby('ClusterLabel')[numeric_cols].mean()
        cluster_numeric_mean.to_csv(f"{OUTPUT_DIR}/cluster_numeric_mean.csv")

        # Tamanho de cada cluster
        cluster_counts = df['ClusterLabel'].value_counts()
        cluster_counts.to_csv(f"{OUTPUT_DIR}/cluster_size.csv")

        # Gr√°fico de distribui√ß√£o de clusters com porcentagens (NOVO)
        plt.figure(figsize=(10, 6))
        percentages = (cluster_counts / len(df) * 100).round(1)

        ax = sns.barplot(x=cluster_counts.index, y=cluster_counts.values, palette="viridis")

        # Adicionando porcentagens
        for i, p in enumerate(ax.patches):
            height = p.get_height()
            ax.text(p.get_x() + p.get_width() / 2., height + 3,
                    f'{percentages.iloc[i]}%',
                    ha="center", va="bottom", fontsize=10)

        plt.title('Distribui√ß√£o de Clientes por Cluster')
        plt.xlabel('Cluster')
        plt.ylabel('Quantidade')
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.savefig(f"{OUTPUT_DIR}/cluster_distribution.png")
        plt.close()

        # Boxplot de cada coluna num√©rica, separado por ClusterLabel
        for col in numeric_cols:
            plt.figure(figsize=(8, 5))
            sns.boxplot(x='ClusterLabel', y=col, data=df, palette='viridis')
            plt.title(f'Distribui√ß√£o de {col} por Cluster')
            plt.savefig(f"{OUTPUT_DIR}/box_cluster_{col}.png")
            plt.close()

        print(" Sum√°rios por cluster salvos (cluster_numeric_mean.csv, cluster_size.csv).")

    elif 'Cluster' in df.columns:
        # Mesma l√≥gica, mas usando a coluna 'Cluster' se preferir
        cluster_numeric_mean = df.groupby('Cluster')[numeric_cols].mean()
        cluster_numeric_mean.to_csv(f"{OUTPUT_DIR}/cluster_numeric_mean.csv")

        cluster_counts = df['Cluster'].value_counts()
        cluster_counts.to_csv(f"{OUTPUT_DIR}/cluster_size.csv")

        # Gr√°fico de distribui√ß√£o de clusters com porcentagens (NOVO)
        plt.figure(figsize=(10, 6))
        percentages = (cluster_counts / len(df) * 100).round(1)

        ax = sns.barplot(x=cluster_counts.index, y=cluster_counts.values, palette="viridis")

        # Adicionando porcentagens
        for i, p in enumerate(ax.patches):
            height = p.get_height()
            ax.text(p.get_x() + p.get_width() / 2., height + 3,
                    f'{percentages.iloc[i]}%',
                    ha="center", va="bottom", fontsize=10)

        plt.title('Distribui√ß√£o de Clientes por Cluster')
        plt.xlabel('Cluster')
        plt.ylabel('Quantidade')
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.savefig(f"{OUTPUT_DIR}/cluster_distribution.png")
        plt.close()

        for col in numeric_cols:
            plt.figure(figsize=(8, 5))
            sns.boxplot(x='Cluster', y=col, data=df, palette='viridis')
            plt.title(f'Distribui√ß√£o de {col} por Cluster')
            plt.savefig(f"{OUTPUT_DIR}/box_cluster_{col}.png")
            plt.close()

        print(" Sum√°rios por cluster salvos (cluster_numeric_mean.csv, cluster_size.csv).")


def generate_report(df):
    """Gera um relat√≥rio textual final com as principais informa√ß√µes."""
    num_rows, num_cols = df.shape
    num_numeric = len(df.select_dtypes(include=[np.number]).columns)
    num_categorical = len(df.select_dtypes(include=['object', 'category']).columns)

    # Se houver a coluna ClusterLabel ou Cluster, calculamos a distribui√ß√£o
    cluster_col = 'ClusterLabel' if 'ClusterLabel' in df.columns else ('Cluster' if 'Cluster' in df.columns else None)
    if cluster_col:
        cluster_counts = df[cluster_col].value_counts(normalize=True) * 100
    else:
        cluster_counts = {}

    report_content = f"""
    üìã Relat√≥rio de An√°lise - {datetime.now().strftime('%Y-%m-%d %H:%M')}
    ------------------------------------------------------------
    ‚Ä¢ Dimens√µes do dataset: {num_rows} linhas x {num_cols} colunas
    ‚Ä¢ Mem√≥ria utilizada: {df.memory_usage().sum() / 1024 ** 2:.2f} MB
    ‚Ä¢ Colunas num√©ricas: {num_numeric}
    ‚Ä¢ Colunas categ√≥ricas: {num_categorical}

    ‚Ä¢ Distribui√ß√£o dos Clusters:
    {cluster_counts.to_string() if cluster_col else 'Nenhuma coluna de cluster encontrada.'}
    """

    with open(f"{OUTPUT_DIR}/analysis_report.txt", "w") as f:
        f.write(report_content)

    print(f"\n Relat√≥rio salvo em: {OUTPUT_DIR}/analysis_report.txt")


def main():
    df = load_data()
    if df is not None:
        df = optimize_memory(df)
        df = clean_data(df)
        if df is None:
            print(" Erro: O dataset ficou vazio ap√≥s a limpeza. Revise os filtros.")
        else:
            # EXEMPLO: Segmentar e atribuir nomes
            df = segment_clients(df, n_clusters=4)  # Ajuste n_clusters conforme necess√°rio
            if 'Cluster' not in df.columns:
                print(" Erro: A segmenta√ß√£o falhou. Verifique os dados de entrada.")
            else:
                # Se quiser nomes amig√°veis baseados em alguma coluna, por exemplo 'categoria'
                # Se n√£o tiver essa coluna, pode ignorar
                cluster_names = assign_cluster_names(df, col_name='categoria')
                df['ClusterLabel'] = df['Cluster'].map(cluster_names)

            # Agora fazemos a EDA completa
            comprehensive_eda(df)

            # E por fim, geramos o relat√≥rio textual
            generate_report(df)

            print(f"\n An√°lise conclu√≠da! Resultados salvos em: {OUTPUT_DIR}")
    else:
        print(" Erro: N√£o foi poss√≠vel carregar os dados.")


if __name__ == "__main__":
    main()